{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_set(json_data):\n",
    "    feature_set = set()\n",
    "    for occupation, info in json_data.items():\n",
    "        for feature in info['attribute']:\n",
    "            # print(feature)\n",
    "            feature_set.add(feature)\n",
    "    return feature_set\n",
    "\n",
    "data = load_data('output/occupation_attribute_100.json')\n",
    "feature_set = get_feature_set(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acceptability',\n",
       " 'acting',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'address',\n",
       " 'air',\n",
       " 'album',\n",
       " 'alvin',\n",
       " 'american',\n",
       " 'andy',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'announcer',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appointed',\n",
       " 'april',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'army',\n",
       " 'arranger',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'ascent',\n",
       " 'athlete',\n",
       " 'author',\n",
       " 'automobile',\n",
       " 'award',\n",
       " 'ballet',\n",
       " 'band',\n",
       " 'baptist',\n",
       " 'berkeley',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bible',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'book',\n",
       " 'boyd',\n",
       " 'british',\n",
       " 'broadcast',\n",
       " 'broadcaster',\n",
       " 'broadcasting',\n",
       " 'broadway',\n",
       " 'brower',\n",
       " 'building',\n",
       " 'bulgarian',\n",
       " 'business',\n",
       " 'businessman',\n",
       " 'businesswoman',\n",
       " 'cabinet',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cannes',\n",
       " 'career',\n",
       " 'carpenter',\n",
       " 'cathedral',\n",
       " 'centre',\n",
       " 'ceo',\n",
       " 'ceylon',\n",
       " 'chairman',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'chart',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'christian',\n",
       " 'church',\n",
       " 'cinema',\n",
       " 'city',\n",
       " 'classical',\n",
       " 'climb',\n",
       " 'climbed',\n",
       " 'climber',\n",
       " 'climbing',\n",
       " 'club',\n",
       " 'coach',\n",
       " 'college',\n",
       " 'column',\n",
       " 'columnist',\n",
       " 'comedian',\n",
       " 'comedy',\n",
       " 'commander',\n",
       " 'communist',\n",
       " 'company',\n",
       " 'composed',\n",
       " 'composer',\n",
       " 'concert',\n",
       " 'conductor',\n",
       " 'congress',\n",
       " 'corp',\n",
       " 'cortijo',\n",
       " 'country',\n",
       " 'court',\n",
       " 'covert',\n",
       " 'critic',\n",
       " 'cross',\n",
       " 'cup',\n",
       " 'currently',\n",
       " 'dance',\n",
       " 'dancehall',\n",
       " 'dancer',\n",
       " 'data',\n",
       " 'davenport',\n",
       " 'de',\n",
       " 'debut',\n",
       " 'december',\n",
       " 'deejay',\n",
       " 'deen',\n",
       " 'democratic',\n",
       " 'deputy',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'development',\n",
       " 'died',\n",
       " 'directed',\n",
       " 'director',\n",
       " 'district',\n",
       " 'drama',\n",
       " 'economic',\n",
       " 'economics',\n",
       " 'economist',\n",
       " 'editor',\n",
       " 'education',\n",
       " 'educator',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'english',\n",
       " 'entertainer',\n",
       " 'entertainment',\n",
       " 'entitled',\n",
       " 'entrepreneur',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'environmentalist',\n",
       " 'essay',\n",
       " 'essayist',\n",
       " 'european',\n",
       " 'event',\n",
       " 'everest',\n",
       " 'executive',\n",
       " 'expedition',\n",
       " 'exposure',\n",
       " 'fashion',\n",
       " 'festival',\n",
       " 'fiction',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finance',\n",
       " 'first',\n",
       " 'fitness',\n",
       " 'fleming',\n",
       " 'force',\n",
       " 'former',\n",
       " 'founded',\n",
       " 'founder',\n",
       " 'francis',\n",
       " 'frankfurt',\n",
       " 'fraternity',\n",
       " 'french',\n",
       " 'frost',\n",
       " 'game',\n",
       " 'general',\n",
       " 'geographer',\n",
       " 'geographical',\n",
       " 'geography',\n",
       " 'george',\n",
       " 'german',\n",
       " 'germany',\n",
       " 'gold',\n",
       " 'government',\n",
       " 'green',\n",
       " 'group',\n",
       " 'gruppman',\n",
       " 'guitar',\n",
       " 'guitarist',\n",
       " 'head',\n",
       " 'hill',\n",
       " 'hip',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hockey',\n",
       " 'hop',\n",
       " 'host',\n",
       " 'house',\n",
       " 'houston',\n",
       " 'human',\n",
       " 'ice',\n",
       " 'igor',\n",
       " 'including',\n",
       " 'incorporators',\n",
       " 'india',\n",
       " 'indian',\n",
       " 'instructor',\n",
       " 'interior',\n",
       " 'international',\n",
       " 'jamaica',\n",
       " 'jamaican',\n",
       " 'january',\n",
       " 'jazz',\n",
       " 'joan',\n",
       " 'john',\n",
       " 'journalist',\n",
       " 'july',\n",
       " 'june',\n",
       " 'justice',\n",
       " 'kappa',\n",
       " 'kingston',\n",
       " 'label',\n",
       " 'landscape',\n",
       " 'language',\n",
       " 'law',\n",
       " 'lawyer',\n",
       " 'leader',\n",
       " 'leaf',\n",
       " 'league',\n",
       " 'lee',\n",
       " 'legislature',\n",
       " 'life',\n",
       " 'light',\n",
       " 'linguist',\n",
       " 'literary',\n",
       " 'literature',\n",
       " 'locksmith',\n",
       " 'london',\n",
       " 'lord',\n",
       " 'lost',\n",
       " 'louisiana',\n",
       " 'made',\n",
       " 'magazine',\n",
       " 'magician',\n",
       " 'manitoba',\n",
       " 'many',\n",
       " 'mao',\n",
       " 'maple',\n",
       " 'march',\n",
       " 'married',\n",
       " 'martial',\n",
       " 'master',\n",
       " 'may',\n",
       " 'mayor',\n",
       " 'mccallum',\n",
       " 'mccleester',\n",
       " 'medal',\n",
       " 'medical',\n",
       " 'medium',\n",
       " 'member',\n",
       " 'messaging',\n",
       " 'mexican',\n",
       " 'military',\n",
       " 'minister',\n",
       " 'ministry',\n",
       " 'miss',\n",
       " 'model',\n",
       " 'morning',\n",
       " 'moscow',\n",
       " 'mount',\n",
       " 'mountain',\n",
       " 'mountaineer',\n",
       " 'movement',\n",
       " 'movie',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'musician',\n",
       " 'myrander',\n",
       " 'named',\n",
       " 'narrated',\n",
       " 'narrator',\n",
       " 'national',\n",
       " 'navy',\n",
       " 'network',\n",
       " 'new',\n",
       " 'news',\n",
       " 'newspaper',\n",
       " 'northwest',\n",
       " 'novel',\n",
       " 'novelist',\n",
       " 'november',\n",
       " 'october',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'olympic',\n",
       " 'olympics',\n",
       " 'orchestra',\n",
       " 'organ',\n",
       " 'organist',\n",
       " 'pa',\n",
       " 'paper',\n",
       " 'park',\n",
       " 'parliament',\n",
       " 'parliamentary',\n",
       " 'party',\n",
       " 'pastor',\n",
       " 'paul',\n",
       " 'peak',\n",
       " 'peer',\n",
       " 'people',\n",
       " 'personality',\n",
       " 'philanthropist',\n",
       " 'philharmonic',\n",
       " 'piano',\n",
       " 'picture',\n",
       " 'play',\n",
       " 'played',\n",
       " 'player',\n",
       " 'playwright',\n",
       " 'poem',\n",
       " 'poet',\n",
       " 'poetry',\n",
       " 'political',\n",
       " 'politician',\n",
       " 'president',\n",
       " 'produced',\n",
       " 'producer',\n",
       " 'production',\n",
       " 'professor',\n",
       " 'program',\n",
       " 'project',\n",
       " 'provided',\n",
       " 'prussia',\n",
       " 'public',\n",
       " 'published',\n",
       " 'puerto',\n",
       " 'radio',\n",
       " 'rapper',\n",
       " 'reality',\n",
       " 'received',\n",
       " 'record',\n",
       " 'recorded',\n",
       " 'recording',\n",
       " 'red',\n",
       " 'reggae',\n",
       " 'relationship',\n",
       " 'released',\n",
       " 'replaced',\n",
       " 'represented',\n",
       " 'representing',\n",
       " 'republic',\n",
       " 'republican',\n",
       " 'research',\n",
       " 'revolution',\n",
       " 'revolutionary',\n",
       " 'richard',\n",
       " 'rico',\n",
       " 'right',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'romanian',\n",
       " 'round',\n",
       " 'roxas',\n",
       " 'royal',\n",
       " 'rugby',\n",
       " 'russian',\n",
       " 'sc',\n",
       " 'school',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'screenplay',\n",
       " 'screenwriter',\n",
       " 'season',\n",
       " 'senior',\n",
       " 'september',\n",
       " 'series',\n",
       " 'served',\n",
       " 'several',\n",
       " 'severing',\n",
       " 'sherpa',\n",
       " 'shooter',\n",
       " 'short',\n",
       " 'show',\n",
       " 'sigma',\n",
       " 'since',\n",
       " 'singer',\n",
       " 'single',\n",
       " 'sir',\n",
       " 'society',\n",
       " 'solo',\n",
       " 'soloist',\n",
       " 'song',\n",
       " 'songwriter',\n",
       " 'south',\n",
       " 'sport',\n",
       " 'sportsman',\n",
       " 'sri',\n",
       " 'stage',\n",
       " 'starred',\n",
       " 'starring',\n",
       " 'state',\n",
       " 'station',\n",
       " 'story',\n",
       " 'study',\n",
       " 'stunt',\n",
       " 'stuntman',\n",
       " 'summit',\n",
       " 'sun',\n",
       " 'surgeon',\n",
       " 'talk',\n",
       " 'teacher',\n",
       " 'team',\n",
       " 'television',\n",
       " 'term',\n",
       " 'territory',\n",
       " 'texas',\n",
       " 'text',\n",
       " 'theatre',\n",
       " 'thesis',\n",
       " 'three',\n",
       " 'time',\n",
       " 'tisziji',\n",
       " 'toronto',\n",
       " 'translation',\n",
       " 'translator',\n",
       " 'travel',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'txting',\n",
       " 'uganda',\n",
       " 'union',\n",
       " 'united',\n",
       " 'university',\n",
       " 'updf',\n",
       " 'video',\n",
       " 'voice',\n",
       " 'war',\n",
       " 'washington',\n",
       " 'well',\n",
       " 'western',\n",
       " 'white',\n",
       " 'winnipeg',\n",
       " 'woman',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'world',\n",
       " 'writer',\n",
       " 'writing',\n",
       " 'wrote',\n",
       " 'year',\n",
       " 'yoga',\n",
       " 'york'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def build_probability_matrix_from_list(data, feature_set):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    feature_counts = Counter()\n",
    "    co_occurrence_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Process each occupation group in the data\n",
    "    for summary in tqdm(data, desc=\"Processing occupations\"):\n",
    "        words = word_tokenize(summary.lower())\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word.isalpha()]\n",
    "        features_in_summary = [word for word in lemmatized_words if word in feature_set]\n",
    "\n",
    "        in_this_summary = set()\n",
    "\n",
    "        for i in range(len(features_in_summary)):\n",
    "            for j in range(i + 1, len(features_in_summary)):\n",
    "                if (features_in_summary[i],features_in_summary[j]) not in in_this_summary:\n",
    "                    in_this_summary.add((features_in_summary[i], features_in_summary[j]))\n",
    "                    feature_counts[features_in_summary[i]] += 1\n",
    "                    co_occurrence_counts[features_in_summary[i]][features_in_summary[j]] += 1\n",
    "\n",
    "    feature_list = sorted(feature_set)\n",
    "    matrix_size = len(feature_list)\n",
    "    probability_matrix = np.zeros((matrix_size, matrix_size))\n",
    "    \n",
    "    for i, f1 in enumerate(feature_list):\n",
    "        total_co_occurrences = sum(co_occurrence_counts[f1].values())\n",
    "        for j, f2 in enumerate(feature_list):\n",
    "            # if f1 != f2 and total_co_occurrences > 0:\n",
    "            if total_co_occurrences > 0:\n",
    "                probability_matrix[i, j] = co_occurrence_counts[f1][f2] / total_co_occurrences\n",
    "\n",
    "    return feature_list, probability_matrix, feature_counts, co_occurrence_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing occupations: 100%|██████████| 105840/105840 [01:44<00:00, 1015.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# json_file = 'output/occupation_data_100.json'\n",
    "json_file = 'output/occupation_summaries_200.json'\n",
    "data = load_data(json_file)\n",
    "wiki_summary_list = [i for i in data.values()]\n",
    "feature_list, prob_matrix, feature_counts, co_occurrence_counts = build_probability_matrix_from_list(wiki_summary_list, feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_outputs(feature_list, probability_matrix, feature_counts, co_occurrence_counts, output_prefix):\n",
    "    # Save the feature list\n",
    "    with open(f'{output_prefix}_feature_list.json', 'w') as f:\n",
    "        json.dump(feature_list, f, indent=4)\n",
    "    \n",
    "    # Save the probability matrix using NumPy's save function\n",
    "    np.save(f'{output_prefix}_probability_matrix.npy', probability_matrix)\n",
    "    \n",
    "    # Save the feature counts\n",
    "    with open(f'{output_prefix}_feature_counts.json', 'w') as f:\n",
    "        json.dump(dict(feature_counts), f, indent=4)\n",
    "    \n",
    "    # Save the co_occurrence counts\n",
    "    with open(f'{output_prefix}_co_occurrence_counts.json', 'w') as f:\n",
    "        # Convert defaultdict to a normal dictionary for JSON serialization\n",
    "        co_occurrence_dict = {k: dict(v) for k, v in co_occurrence_counts.items()}\n",
    "        json.dump(co_occurrence_dict, f, indent=4)\n",
    "\n",
    "save_outputs(feature_list, prob_matrix, feature_counts, co_occurrence_counts, 'output/wiki_allow_same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sorted_probabilities(feature_list, probability_matrix, feature_counts, co_occurrence_counts, output_file):\n",
    "    feature_index = {feature: idx for idx, feature in enumerate(feature_list)}\n",
    "    sorted_probabilities = []\n",
    "\n",
    "    # Collect all relevant data\n",
    "    for f1 in feature_list:\n",
    "        for f2 in feature_list:\n",
    "            f1_idx = feature_index[f1]\n",
    "            f2_idx = feature_index[f2]\n",
    "            prob = probability_matrix[f1_idx][f2_idx]\n",
    "            f1_count = feature_counts[f1]\n",
    "            co_occurrence = co_occurrence_counts[f1][f2]\n",
    "            sorted_probabilities.append(((f1, f2), prob, f1_count, co_occurrence))\n",
    "\n",
    "    # Sort by probability, descending\n",
    "    sorted_probabilities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for entry in sorted_probabilities:\n",
    "            line = f\"{entry[0]}: Probability={entry[1]:.4f}, Count of {entry[0][0]}={entry[2]}, Count of {entry[0][0]} followed by {entry[0][1]}={entry[3]}\\n\"\n",
    "            file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'wiki_allow_same_sorted_probabilities_report.txt'\n",
    "save_sorted_probabilities(feature_list, prob_matrix, feature_counts, co_occurrence_counts, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data_from_jsonl(jsonl_files):\n",
    "    data = []\n",
    "    for file_path in jsonl_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                # Each line is a complete JSON object\n",
    "                entry = json.loads(line)\n",
    "                data.append(entry)\n",
    "    return data\n",
    "\n",
    "unlabeled_path = Path('data/unlabeled')\n",
    "labeled_path = Path('data/labeled')\n",
    "jsonl_files = list(unlabeled_path.glob('*.jsonl'))+list(labeled_path.glob('*.jsonl'))######\n",
    "all_data = load_data_from_jsonl(jsonl_files)\n",
    "gen_output_list = [i['output'] for i in all_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/unlabeled/Alpaca-13B.jsonl'),\n",
       " PosixPath('data/unlabeled/Alpaca-65B.jsonl'),\n",
       " PosixPath('data/unlabeled/Alpaca-7B.jsonl'),\n",
       " PosixPath('data/unlabeled/ChatGPT.jsonl'),\n",
       " PosixPath('data/unlabeled/Dolly-12B.jsonl'),\n",
       " PosixPath('data/unlabeled/Pythia-12B.jsonl'),\n",
       " PosixPath('data/unlabeled/GPT-4.jsonl'),\n",
       " PosixPath('data/unlabeled/InstructGPT.jsonl'),\n",
       " PosixPath('data/unlabeled/MPT-Chat-7B.jsonl'),\n",
       " PosixPath('data/unlabeled/Stablelm-alpha-7B.jsonl'),\n",
       " PosixPath('data/unlabeled/Vicuna-13B.jsonl'),\n",
       " PosixPath('data/unlabeled/Vicuna-7B.jsonl'),\n",
       " PosixPath('data/labeled/ChatGPT.jsonl'),\n",
       " PosixPath('data/labeled/InstructGPT.jsonl'),\n",
       " PosixPath('data/labeled/PerplexityAI.jsonl')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing occupations: 100%|██████████| 6549/6549 [00:08<00:00, 811.47it/s] \n"
     ]
    }
   ],
   "source": [
    "feature_list_gen, prob_matrix_gen, feature_counts_gen, co_occurrence_counts_gen = build_probability_matrix_from_list(gen_output_list, feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_outputs(feature_list_gen, prob_matrix_gen, feature_counts_gen, co_occurrence_counts_gen, 'output/gen_allow_same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'gen_allow_same_sorted_probabilities_report.txt'\n",
    "save_sorted_probabilities(feature_list_gen, prob_matrix_gen, feature_counts_gen, co_occurrence_counts_gen, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_probability_matrices(wiki_matrix, gen_matrix, feature_list, output_file):\n",
    "\n",
    "    matrix_size = len(feature_list)\n",
    "    differences = np.zeros((matrix_size, matrix_size))\n",
    "    \n",
    "    for i in range(matrix_size):\n",
    "        for j in range(matrix_size):\n",
    "            differences[i][j] = gen_matrix[i][j] - wiki_matrix[i][j]\n",
    "\n",
    "    # print(differences)\n",
    "\n",
    "    flat_differences = []\n",
    "    for i in range(matrix_size):\n",
    "        for j in range(matrix_size):\n",
    "            flat_differences.append(((feature_list[i], feature_list[j]), differences[i][j]))\n",
    "\n",
    "    flat_differences.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    significant_differences = {\n",
    "        'most_positive': flat_differences[:20], \n",
    "        'most_negative': flat_differences[-20:] \n",
    "    }\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(significant_differences, f, indent=4)\n",
    "\n",
    "    return significant_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n",
      "443\n",
      "443\n"
     ]
    }
   ],
   "source": [
    "print(len(prob_matrix))\n",
    "print(len(feature_list))\n",
    "print(len(prob_matrix_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wiki_prob_matrix = prob_matrix\n",
    "gen_prob_matrix = prob_matrix_gen\n",
    "feature_list = feature_list\n",
    "\n",
    "output_file_path = 'comparison_results_allow_same.json'\n",
    "comparison_results = compare_probability_matrices(wiki_prob_matrix, gen_prob_matrix, feature_list, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build buckets and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten_matrix(matrix, feature_list):\n",
    "    flattened_data = []\n",
    "    for i in range(len(feature_list)):\n",
    "        for j in range(len(feature_list)):\n",
    "            value = matrix[i, j]\n",
    "            flattened_data.append((feature_list[i], feature_list[j], value))\n",
    "    return flattened_data\n",
    "\n",
    "wiki_flattened = flatten_matrix(prob_matrix, feature_list)\n",
    "gen_flattened = flatten_matrix(prob_matrix_gen, feature_list_gen)\n",
    "\n",
    "wiki_df = pd.DataFrame(wiki_flattened, columns=['Feature1', 'Feature2', 'Wiki_Prob'])\n",
    "gen_df = pd.DataFrame(gen_flattened, columns=['Feature1', 'Feature2', 'Gen_Prob'])\n",
    "\n",
    "comparison_df = pd.merge(wiki_df, gen_df, on=['Feature1', 'Feature2'], how='inner')\n",
    "comparison_df = comparison_df[comparison_df['Wiki_Prob'] != 0]\n",
    "comparison_df = comparison_df[comparison_df['Gen_Prob'] != 0]\n",
    "\n",
    "comparison_df['Wiki_Bucket'] = pd.qcut(comparison_df['Wiki_Prob'], 5, labels=False) + 1\n",
    "comparison_df['Gen_Bucket'] = pd.qcut(comparison_df['Gen_Prob'], 5, labels=False) + 1\n",
    "\n",
    "comparison_df['Change'] = comparison_df['Gen_Prob'] - comparison_df['Wiki_Prob']\n",
    "comparison_df['Change_Direction'] = comparison_df['Change'].apply(lambda x: 'Increase' if x > 0 else ('Decrease' if x < 0 else 'No Change'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Wiki_Prob</th>\n",
       "      <th>Gen_Prob</th>\n",
       "      <th>Wiki_Bucket</th>\n",
       "      <th>Gen_Bucket</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change_Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>acting</td>\n",
       "      <td>acting</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>acting</td>\n",
       "      <td>actor</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>acting</td>\n",
       "      <td>actress</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>acting</td>\n",
       "      <td>address</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>acting</td>\n",
       "      <td>air</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196243</th>\n",
       "      <td>york</td>\n",
       "      <td>writer</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.002707</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196244</th>\n",
       "      <td>york</td>\n",
       "      <td>writing</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196245</th>\n",
       "      <td>york</td>\n",
       "      <td>wrote</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196246</th>\n",
       "      <td>york</td>\n",
       "      <td>year</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196248</th>\n",
       "      <td>york</td>\n",
       "      <td>york</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature1 Feature2  Wiki_Prob  Gen_Prob  Wiki_Bucket  Gen_Bucket  \\\n",
       "444      acting   acting   0.013720  0.024896            5           5   \n",
       "445      acting    actor   0.015059  0.021935            5           5   \n",
       "446      acting  actress   0.009742  0.015025            5           5   \n",
       "447      acting  address   0.000116  0.000110            1           1   \n",
       "448      acting      air   0.001029  0.000219            2           1   \n",
       "...         ...      ...        ...       ...          ...         ...   \n",
       "196243     york   writer   0.006027  0.003320            5           4   \n",
       "196244     york  writing   0.005166  0.004006            4           4   \n",
       "196245     york    wrote   0.005308  0.002862            4           3   \n",
       "196246     york     year   0.014373  0.009501            5           5   \n",
       "196248     york     york   0.020592  0.019574            5           5   \n",
       "\n",
       "          Change Change_Direction  \n",
       "444     0.011175         Increase  \n",
       "445     0.006875         Increase  \n",
       "446     0.005283         Increase  \n",
       "447    -0.000007         Decrease  \n",
       "448    -0.000809         Decrease  \n",
       "...          ...              ...  \n",
       "196243 -0.002707         Decrease  \n",
       "196244 -0.001159         Decrease  \n",
       "196245 -0.002446         Decrease  \n",
       "196246 -0.004872         Decrease  \n",
       "196248 -0.001018         Decrease  \n",
       "\n",
       "[89219 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen_Bucket       1     2     3     4      5\n",
      "Wiki_Bucket                                \n",
      "1            10019  4523  2155   859    288\n",
      "2             5124  5939  4045  2049    687\n",
      "3             2117  4852  5583  3828   1463\n",
      "4              558  2203  4874  6591   3618\n",
      "5               64   325  1158  4509  11788\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate the stats of how many pairs move from each original bucket to each new bucket\n",
    "bucket_movement = comparison_df.groupby(['Wiki_Bucket', 'Gen_Bucket']).size().unstack(fill_value=0)\n",
    "print(bucket_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "count    17844.000000\n",
      "mean         0.000690\n",
      "std          0.001905\n",
      "min         -0.000648\n",
      "25%         -0.000043\n",
      "50%          0.000188\n",
      "75%          0.000741\n",
      "max          0.045911\n",
      "Name: Change, dtype: float64\n",
      "2\n",
      "count    17844.000000\n",
      "mean         0.000725\n",
      "std          0.002984\n",
      "min         -0.001540\n",
      "25%         -0.000553\n",
      "50%         -0.000073\n",
      "75%          0.000907\n",
      "max          0.075675\n",
      "Name: Change, dtype: float64\n",
      "3\n",
      "count    17843.000000\n",
      "mean         0.000648\n",
      "std          0.003918\n",
      "min         -0.002940\n",
      "25%         -0.001224\n",
      "50%         -0.000444\n",
      "75%          0.001025\n",
      "max          0.085000\n",
      "Name: Change, dtype: float64\n",
      "4\n",
      "count    17844.000000\n",
      "mean         0.000675\n",
      "std          0.005249\n",
      "min         -0.005624\n",
      "25%         -0.002177\n",
      "50%         -0.000777\n",
      "75%          0.001656\n",
      "max          0.128205\n",
      "Name: Change, dtype: float64\n",
      "5\n",
      "count    17844.000000\n",
      "mean         0.002067\n",
      "std          0.010190\n",
      "min         -0.151061\n",
      "25%         -0.003473\n",
      "50%         -0.000219\n",
      "75%          0.005090\n",
      "max          0.242579\n",
      "Name: Change, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(i)\n",
    "    print(comparison_df[comparison_df['Wiki_Bucket'] == i]['Change'].describe(include=['O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Wiki_Prob</th>\n",
       "      <th>Gen_Prob</th>\n",
       "      <th>Wiki_Bucket</th>\n",
       "      <th>Gen_Bucket</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change_Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>acceptability</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>deputy</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>economic</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>elected</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>election</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196244</th>\n",
       "      <td>york</td>\n",
       "      <td>writing</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196245</th>\n",
       "      <td>york</td>\n",
       "      <td>wrote</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196246</th>\n",
       "      <td>york</td>\n",
       "      <td>year</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196247</th>\n",
       "      <td>york</td>\n",
       "      <td>yoga</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196248</th>\n",
       "      <td>york</td>\n",
       "      <td>york</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163279 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature1       Feature2  Wiki_Prob  Gen_Prob  Wiki_Bucket  \\\n",
       "0       acceptability  acceptability   0.027027  0.000000            5   \n",
       "114     acceptability         deputy   0.027027  0.000000            5   \n",
       "123     acceptability       economic   0.027027  0.000000            5   \n",
       "129     acceptability        elected   0.027027  0.000000            5   \n",
       "130     acceptability       election   0.027027  0.000000            5   \n",
       "...               ...            ...        ...       ...          ...   \n",
       "196244           york        writing   0.005166  0.004006            5   \n",
       "196245           york          wrote   0.005308  0.002862            5   \n",
       "196246           york           year   0.014373  0.009501            5   \n",
       "196247           york           yoga   0.000041  0.000000            1   \n",
       "196248           york           york   0.020592  0.019574            5   \n",
       "\n",
       "        Gen_Bucket    Change Change_Direction  \n",
       "0                1 -0.027027         Decrease  \n",
       "114              1 -0.027027         Decrease  \n",
       "123              1 -0.027027         Decrease  \n",
       "129              1 -0.027027         Decrease  \n",
       "130              1 -0.027027         Decrease  \n",
       "...            ...       ...              ...  \n",
       "196244           1 -0.001159         Decrease  \n",
       "196245           1 -0.002446         Decrease  \n",
       "196246           1 -0.004872         Decrease  \n",
       "196247           1 -0.000041         Decrease  \n",
       "196248           1 -0.001018         Decrease  \n",
       "\n",
       "[163279 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df2 = pd.merge(wiki_df, gen_df, on=['Feature1', 'Feature2'], how='inner')\n",
    "comparison_df2 = comparison_df2[comparison_df2['Wiki_Prob'] != 0]\n",
    "\n",
    "comparison_df2['Wiki_Bucket'] = pd.qcut(comparison_df2['Wiki_Prob'], 5, labels=False) + 1\n",
    "comparison_df2['Gen_Bucket'] = pd.cut(comparison_df2['Gen_Prob'], bins=5, labels=False) + 1\n",
    "\n",
    "comparison_df2['Change'] = comparison_df2['Gen_Prob'] - comparison_df2['Wiki_Prob']\n",
    "comparison_df2['Change_Direction'] = comparison_df2['Change'].apply(lambda x: 'Increase' if x > 0 else ('Decrease' if x < 0 else 'No Change'))\n",
    "\n",
    "comparison_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen_Bucket       1     2     3     4      5\n",
      "Wiki_Bucket                                \n",
      "1            10019  4523  2155   859    288\n",
      "2             5124  5939  4045  2049    687\n",
      "3             2117  4852  5583  3828   1463\n",
      "4              558  2203  4874  6591   3618\n",
      "5               64   325  1158  4509  11788\n"
     ]
    }
   ],
   "source": [
    "bucket_movement = comparison_df.groupby(['Wiki_Bucket', 'Gen_Bucket']).size().unstack(fill_value=0)\n",
    "print(bucket_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "count    17844.000000\n",
      "mean         0.000690\n",
      "std          0.001905\n",
      "min         -0.000648\n",
      "25%         -0.000043\n",
      "50%          0.000188\n",
      "75%          0.000741\n",
      "max          0.045911\n",
      "Name: Change, dtype: float64\n",
      "2\n",
      "count    17844.000000\n",
      "mean         0.000725\n",
      "std          0.002984\n",
      "min         -0.001540\n",
      "25%         -0.000553\n",
      "50%         -0.000073\n",
      "75%          0.000907\n",
      "max          0.075675\n",
      "Name: Change, dtype: float64\n",
      "3\n",
      "count    17843.000000\n",
      "mean         0.000648\n",
      "std          0.003918\n",
      "min         -0.002940\n",
      "25%         -0.001224\n",
      "50%         -0.000444\n",
      "75%          0.001025\n",
      "max          0.085000\n",
      "Name: Change, dtype: float64\n",
      "4\n",
      "count    17844.000000\n",
      "mean         0.000675\n",
      "std          0.005249\n",
      "min         -0.005624\n",
      "25%         -0.002177\n",
      "50%         -0.000777\n",
      "75%          0.001656\n",
      "max          0.128205\n",
      "Name: Change, dtype: float64\n",
      "5\n",
      "count    17844.000000\n",
      "mean         0.002067\n",
      "std          0.010190\n",
      "min         -0.151061\n",
      "25%         -0.003473\n",
      "50%         -0.000219\n",
      "75%          0.005090\n",
      "max          0.242579\n",
      "Name: Change, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(i)\n",
    "    print(comparison_df[comparison_df['Wiki_Bucket'] == i]['Change'].describe(include=['O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333.4381765430599\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df['Wiki_Prob'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419.1609584040059\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df['Gen_Prob'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442.99999999999994\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df2['Wiki_Prob'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419.1609584040059\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df2['Gen_Prob'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factscore",
   "language": "python",
   "name": "factscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
